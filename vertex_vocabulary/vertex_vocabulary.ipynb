{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File count: 32\n",
      "Sample count per file: 15625\n",
      "part-00000-5b54c5d5-bbcf-484d-a2ce-0d6f73df1a36-c000.snappy.parquet\n",
      "Downloading file...\n",
      "Reading in parquet...\n",
      "Index(['SAMPLE_ID', 'URL', 'TEXT', 'HEIGHT', 'WIDTH', 'LICENSE', 'NSFW',\n",
      "       'similarity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import kaggle.api as kaggle\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# The kaggle python API calls below are documented here: https://www.kaggle.com/code/donkeys/kaggle-python-api/notebook\n",
    "\n",
    "# Make sure ~/.kaggle/kaggle.json is set up. If not, go to https://www.kaggle.com/<username>/account to create a new\n",
    "# API token, which downloads a kaggle.json file. Move that file to ~/.kaggle/kaggle.json. Then run the following:\n",
    "kaggle.authenticate()\n",
    "\n",
    "# Get the dataset at https://www.kaggle.com/datasets/romainbeaumont/laion400m\n",
    "dataset = kaggle.dataset_list(user=\"romainbeaumont\", search=\"laion400m\")[0]\n",
    "\n",
    "file_result = kaggle.dataset_list_files(dataset.ref)\n",
    "files = file_result.files\n",
    "# Sort files by file name\n",
    "files.sort(key=lambda x: x.name)\n",
    "\n",
    "# Count the number of files\n",
    "file_count = len(files)\n",
    "# We want to get a random sample of 500,000 rows from the dataset.\n",
    "random_sample_count = 500000\n",
    "sample_count_per_file = random_sample_count // file_count\n",
    "print(f\"File count: {file_count}\")\n",
    "print(f\"Sample count per file: {sample_count_per_file}\")\n",
    "\n",
    "# For now, load the first file in the dataset.\n",
    "# Later, load each file, read sample_count_per_file random rows from it, and delete the file, in this loop\n",
    "for file in files[:1]:\n",
    "    print(file.name)\n",
    "    print(\"Downloading file...\")\n",
    "    kaggle.dataset_download_file(\n",
    "        dataset.ref, file.name, path=file.name, force=False)\n",
    "    # Unzip the file into the same directory as the zip file itself, if it doesn't already exist\n",
    "    if not os.path.exists(f\"{file.name}/{file.name}\"):\n",
    "        print(\"Unzipping file...\")\n",
    "        shutil.unpack_archive(\n",
    "            f\"{file.name}/{file.name}.zip\", extract_dir=file.name, format=\"zip\")\n",
    "\n",
    "    # Load the parquet file into a pandas dataframe\n",
    "    print(\"Reading in parquet...\")\n",
    "    df = pd.read_parquet(f\"{file.name}/{file.name}\")\n",
    "    print(df.columns)\n",
    "    # Filter out rows where the 'HEIGHT' or 'WIDTH' columns are below 224\n",
    "    df = df[(df[\"HEIGHT\"] >= 224) & (df[\"WIDTH\"] >= 224)]\n",
    "    # Get a random subset of sample_count_per_file rows from the dataframe, with a fixed random seed\n",
    "    subset = df.sample(sample_count_per_file, random_state=984324482)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://st6.cannypic.com/thumbs/33/331805_352_canny_pic.jpg\n",
      "http://4.bp.blogspot.com/-OGkrDlRTKVY/UBJ4znKaGaI/AAAAAAAAHDo/lZe7Vk_whvI/s1600/how+to+replace+an+old+sink+faucet+bathroom+tips+%28Large%29.JPG\n",
      "https://cdn.shopify.com/s/files/1/0264/2867/0024/products/2480A-cobi-Tiger-2-P-konigstiger-tank-sd-kfz-182-historical-collection-world-war-2-back-legerspeelgoed.jpg?v=1595796455\n",
      "https://trumpetmediagroup.com/downloads/1948/download/Oscar%20Pistorius%20cries%20as%20the%20%27Not%20Guilty%27%20verdict%20for%20murder%20is%20read%20out%20b.jpg?cb=ce313d7208556efef3ef5eeed3f2e3e3\n",
      "https://i2.wp.com/lessbeatenpaths.hostguardian.com/wp-content/uploads/2013/04/photo-1024x768.jpg?resize=525%2C394\n",
      "https://photos.smugmug.com/Journal/Photo-Journal-2014/2014-November/i-TnZPTMH/0/f777ef5b/XL/ALASKA%20EAGLES%209673-XL.jpg\n",
      "https://cdn.shopify.com/s/files/1/0105/4542/products/deftones-longsleeve_medium.jpg?v=1444668593\n",
      "https://media.gettyimages.com/videos/cologne-cathedral-cologne-north-rhine-westphalia-germany-video-id820854998?s=640x640\n",
      "http://img.costumescenter.com/upload/thumb/360x540/goodsimport/2018-08/PHR0050GY_1.jpg\n",
      "http://4.bp.blogspot.com/_qoJr7kKgahs/TIhhgJ6ZiVI/AAAAAAAAQsM/YoTigRQQPow/s1600/young-Tom-Cruise-12.jpg\n"
     ]
    }
   ],
   "source": [
    "urls = subset[\"URL\"]\n",
    "\n",
    "for url in urls[:10]:\n",
    "    print(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ef0d79ca236209f92ec9c27a5e8bc6a914c9fee5b168cc453dd80be9512a804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
